# 文档处理架构设计文档

## 1. 概述

本文档描述了TK-RAG系统的文档处理架构设计，基于精益开发和敏捷原则，采用队列化处理方式，支持高并发文档处理。

## 2. 架构设计原则

### 2.1 设计原则
- **简单优先**：从最简单的方案开始，避免过度设计
- **渐进式优化**：后续根据需求逐步改进
- **快速验证**：先实现核心功能，快速验证
- **扩展性预留**：为后续扩展预留接口

### 2.2 技术选型
- **队列系统**：Redis + Celery
- **存储策略**：本地文件存储
- **状态管理**：现有doc_info表扩展
- **并发处理**：异步 + 线程池 + 进程池

## 3. 系统架构

### 3.1 整体架构图
```
文档上传 -> Redis队列 -> 预处理队列 -> 解析队列 -> 处理队列 -> 完成
                ↓           ↓           ↓           ↓
            状态回调    状态回调    状态回调    状态回调
```

### 3.2 队列设计
```
主队列（Redis + Celery）：
- 接收所有上传任务
- 任务持久化和状态管理
- 支持任务查询和监控

处理队列（3个）：
- 队列1：预处理（下载 + 格式检测 + 格式转换）
- 队列2：解析（MinerU）
- 队列3：处理（内容处理 + 切块 + 切页）
```

## 4. 状态流转设计

### 4.1 完整状态流转
```
uploaded -> downloading -> ready_to_convert -> converting -> 
ready_to_parse -> parsing -> ready_to_process -> processing -> 
ready_to_chunk -> chunking -> completed
```

### 4.2 状态定义
```python
STATUS_MAPPING = {
    'uploaded': '已上传',
    'downloading': '下载中',
    'download_failed': '下载失败',
    'ready_to_convert': '准备转换',
    'converting': '转换中',
    'convert_failed': '转换失败',
    'ready_to_parse': '准备解析',
    'parsing': '解析中',
    'parse_failed': '解析失败',
    'ready_to_process': '准备处理',
    'processing': '处理中',
    'process_failed': '处理失败',
    'ready_to_chunk': '准备分块',
    'chunking': '分块中',
    'chunk_failed': '分块失败',
    'completed': '处理完成'
}
```

### 4.3 状态回调时机
每个状态变化时都会触发回调：
- uploaded -> downloading
- downloading -> ready_to_convert
- ready_to_convert -> converting
- converting -> ready_to_parse
- ready_to_parse -> parsing
- parsing -> ready_to_process
- ready_to_process -> processing
- processing -> ready_to_chunk
- ready_to_chunk -> chunking
- chunking -> completed

## 5. 并发设计

### 5.1 资源分配（基于128G内存 + 16核32线程 + 48G显存）

#### 队列1（预处理）
```
- 下载：asyncio 异步，10个并发
- 格式检测：asyncio 异步，10个并发
- 格式转换：线程池，4个并发（LibreOffice）
- 内存分配：每个任务500MB，总计约2GB
- 特点：IO密集型，可以较高并发
```

#### 队列2（解析）
```
- MinerU解析：进程池，3个并发（48G显存，每个16G）
- 内存分配：每个进程16GB，总计48GB
- GPU配置：使用pipeline后端，--mem-fraction-static 0.8
- 特点：GPU密集型，资源消耗大
```

#### 队列3（处理）
```
- 内容处理：asyncio 异步，6个并发
- 切块+切页：asyncio 异步，6个并发（原子操作）
- 内存分配：每个任务2GB，总计约12GB
- 特点：CPU + 模型调用，需要平衡资源
```

### 5.2 并发控制策略
```python
# 并发限制配置
CONCURRENCY_CONFIG = {
    'download': 10,        # 下载并发数
    'format_check': 10,    # 格式检测并发数
    'convert': 4,          # 格式转换并发数
    'parse': 3,            # 解析并发数
    'process': 6,          # 内容处理并发数
    'chunk': 6,            # 分块并发数
}
```

## 6. 存储策略

### 6.1 本地文件存储结构
```
temp/
├── {doc_id}/
│   ├── original/          # 原始文件
│   │   ├── source.pdf
│   │   └── metadata.json
│   ├── converted/         # 转换后文件
│   │   ├── document.pdf
│   │   └── metadata.json
│   ├── parsed/           # 解析结果
│   │   ├── layout.json
│   │   ├── spans.json
│   │   └── images/
│   ├── processed/        # 处理结果
│   │   ├── content.json
│   │   └── metadata.json
│   └── chunks/           # 分块结果
│       ├── segments.json
│       ├── pages/
│       └── metadata.json
```

### 6.2 文件管理策略
```python
# 文件管理接口
class FileManager:
    def save_temp_file(doc_id: str, stage: str, content: bytes) -> str
    def get_temp_file(doc_id: str, stage: str) -> bytes
    def cleanup_temp_files(doc_id: str) -> None
    def get_file_path(doc_id: str, stage: str) -> str
```

## 7. 错误处理和重试机制

### 7.1 重试策略
```python
RETRY_CONFIG = {
    'download': {'max_retries': 3, 'delay': 5},
    'convert': {'max_retries': 2, 'delay': 10},
    'parse': {'max_retries': 1, 'delay': 30},  # GPU资源宝贵
    'process': {'max_retries': 2, 'delay': 10},
    'chunk': {'max_retries': 2, 'delay': 10},
}
```

### 7.2 错误回滚策略
- **分层回滚**：已成功处理的环节不清理，只清理当前失败环节的临时文件
- **状态恢复**：支持从失败点重新开始处理
- **资源清理**：失败时自动清理相关资源

## 8. 监控和可观测性

### 8.1 监控指标
```python
MONITORING_METRICS = {
    'queue_length': '队列长度',
    'processing_time': '处理时间',
    'success_rate': '成功率',
    'error_rate': '错误率',
    'resource_usage': '资源使用率',
}
```

### 8.2 日志记录
```python
# 关键日志点
LOG_POINTS = [
    'task_started',      # 任务开始
    'task_completed',    # 任务完成
    'task_failed',       # 任务失败
    'state_changed',     # 状态变化
    'callback_sent',     # 回调发送
    'resource_usage',    # 资源使用
]
```

## 9. 目标代码结构

### 9.1 目录结构
```
tk_rag/
├── docs/                          # 文档目录
│   └── document_processing_architecture.md
├── core/
│   ├── doc/
│   │   ├── __init__.py
│   │   ├── parser.py              # 现有解析逻辑
│   │   ├── chunker.py             # 现有分块逻辑
│   │   ├── loader.py              # 现有加载逻辑
│   │   └── processor.py           # 新增：文档处理器
│   ├── queue/                     # 新增：队列管理
│   │   ├── __init__.py
│   │   ├── task_manager.py        # 任务管理器
│   │   ├── queue_manager.py       # 队列管理器
│   │   └── worker.py              # 工作进程
│   └── storage/                   # 新增：存储管理
│       ├── __init__.py
│       ├── file_manager.py        # 文件管理器
│       └── temp_storage.py        # 临时存储
├── services/
│   ├── doc_server.py              # 现有文档服务
│   └── queue_service.py           # 新增：队列服务
├── config/
│   ├── global_config.py           # 现有配置
│   └── queue_config.py            # 新增：队列配置
└── utils/
    ├── status_sync.py             # 现有状态同步
    └── callback_manager.py        # 新增：回调管理器
```

### 9.2 核心类设计

#### TaskManager（任务管理器）
```python
class TaskManager:
    """任务管理器，负责任务的创建、调度和状态管理"""
    
    def create_task(self, doc_id: str, file_path: str) -> str
    def get_task_status(self, task_id: str) -> dict
    def cancel_task(self, task_id: str) -> bool
    def retry_task(self, task_id: str) -> bool
```

#### QueueManager（队列管理器）
```python
class QueueManager:
    """队列管理器，负责队列的创建、配置和监控"""
    
    def setup_queues(self) -> None
    def get_queue_status(self) -> dict
    def adjust_concurrency(self, queue_name: str, concurrency: int) -> None
```

#### FileManager（文件管理器）
```python
class FileManager:
    """文件管理器，负责临时文件的存储和管理"""
    
    def save_temp_file(self, doc_id: str, stage: str, content: bytes) -> str
    def get_temp_file(self, doc_id: str, stage: str) -> bytes
    def cleanup_temp_files(self, doc_id: str) -> None
    def get_file_path(self, doc_id: str, stage: str) -> str
```

#### CallbackManager（回调管理器）
```python
class CallbackManager:
    """回调管理器，负责状态变化的回调通知"""
    
    def send_callback(self, doc_id: str, status: str, request_id: str = None) -> bool
    def retry_failed_callbacks(self) -> None
    def get_callback_history(self, doc_id: str) -> list
```

## 10. 实施计划

### 10.1 第一阶段：基础功能（1-2周）
1. 实现Redis + Celery队列系统
2. 实现3个处理队列
3. 实现本地文件存储
4. 实现状态回调机制
5. 集成现有解析和分块逻辑

### 10.2 第二阶段：优化完善（1周）
1. 添加监控和日志
2. 优化并发参数
3. 添加错误重试机制
4. 性能测试和调优

### 10.3 第三阶段：扩展功能（后续）
1. 添加更多监控指标
2. 支持动态配置
3. 添加管理界面
4. 支持分布式部署

## 11. 风险评估

### 11.1 技术风险
- **Redis依赖**：Redis服务故障会影响整个系统
- **GPU资源竞争**：多个MinerU进程可能竞争GPU资源
- **磁盘空间**：临时文件可能占用大量磁盘空间

### 11.2 缓解措施
- **Redis高可用**：配置Redis集群或主从复制
- **GPU资源管理**：实现GPU资源池和任务调度
- **磁盘空间管理**：定期清理临时文件，设置磁盘空间监控

## 12. 总结

本架构设计遵循精益开发和敏捷原则，从最简单的方案开始，逐步优化完善。通过队列化处理、状态管理和并发控制，实现了高并发、高可靠的文档处理系统。

关键特性：
- 简单可靠的队列架构
- 清晰的状态流转
- 合理的并发设计
- 完善的错误处理
- 良好的扩展性

该设计为后续的功能扩展和性能优化奠定了良好的基础。 