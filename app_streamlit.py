"""ä½¿ç”¨ streamlit web æ¡†æ¶éƒ¨ç½² RAG é—®ç­”ç³»ç»Ÿ"""

import os
import sys
from typing import List

# Streamlit æ¡†æ¶
import streamlit as st
# Langchain æ¡†æ¶
from langchain.chains import ConversationalRetrievalChain
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_milvus import Milvus

# é¡¹ç›®åŒ…
sys.path.append("/Users/jason/PycharmProjects/tk_rag")
from config import Config, logger
from src.database.build_milvus_db import MilvusDB
from src.llm_generate import process_query, CustomRetriever, create_llm_chain
from src.query_process import init_bm25_retriever


# åˆå§‹åŒ– RAG ç³»ç»Ÿ
@st.cache_resource
def init_rag_chain():
    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    db = MilvusDB()
    db.init_database()

    # åˆå§‹åŒ–embeddings
    logger.info("åˆå§‹åŒ– embeddings æ¨¡å‹...")
    embeddings = HuggingFaceEmbeddings(
        model_name=Config.MODEL_PATHS["embedding"],
        model_kwargs={"device": Config.DEVICE}
    )

    # åˆ›å»º Milvus å‘é‡å­˜å‚¨
    logger.info("åˆå§‹åŒ– Milvus å‘é‡å­˜å‚¨...")
    vectorstore = Milvus(
        embedding_function=embeddings,
        collection_name=Config.MILVUS_CONFIG["collection_name"],
        connection_args={
            "uri": Config.MILVUS_CONFIG["uri"],
            "token": Config.MILVUS_CONFIG["token"],
            "db_name": Config.MILVUS_CONFIG["db_name"], },
        search_params={
            "metric_type": Config.MILVUS_CONFIG["index_params"]["metric_type"],
            "params": Config.MILVUS_CONFIG["search_params"], },
        text_field="text_chunk",
    )

    # åˆå§‹åŒ– BM25 æ£€ç´¢å™¨
    logger.info("åˆå§‹åŒ– BM25 æ£€ç´¢å™¨...")
    bm25_retriever = init_bm25_retriever(db)

    # åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨å¹¶æ·»åŠ æ—¥å¿—
    logger.info("åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨...")
    custom_retriever = CustomRetriever(vectorstore, bm25_retriever)

    # åˆå§‹åŒ– LLM å¯¹è¯é“¾
    llm, memory, chat_prompt, condense_question_prompt = create_llm_chain()

    # åˆ›å»º langchain å¯¹è¯é“¾
    chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=custom_retriever,
        memory=memory,  # ä½¿ç”¨ langchain å†…éƒ¨æœºåˆ¶ä¿å­˜å†å²ä¼šè¯(input,output)
        combine_docs_chain_kwargs={
            "prompt": chat_prompt,
        },
        condense_question_prompt=condense_question_prompt,  # query é‡å†™æ¨¡æ¿
        return_source_documents=True,
        verbose=True,  # è®¾ç½®æ—¥å¿—ä¸º False,é¿å…æ—¥å¿—è¿‡å¤š
    )

    return chain


# é¡µé¢å¸ƒå±€
st.set_page_config(
    page_title="<UNK> RAG <UNK>",
    # page_icon="http://www.xinchan.cn/file/upload/202110/16/1731354666.png",
    page_icon="ğŸ’¬",
    layout="wide",
)
st.title("ğŸ’¬ RAG æ™ºèƒ½çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")

# åˆå§‹åŒ– Chain
chain = init_rag_chain()

# è¾“å…¥æé—®
query = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜: ")

# æäº¤æŒ‰é’®
if st.button("æäº¤"):
    if query.strip():
        with st.spinner("<UNK> æ€è€ƒä¸­ <UNK>..."):
            answer = process_query(query, chain)
            st.success(answer)
    else:
        st.warning("è¯·è¾“å…¥æœ‰æ•ˆé—®é¢˜. ")
